I want a thin coding agent that is tailored to my workflow and needs but remains extendable.

Requirements: 
1. This should be agnostic to LLM provider, but out of the box support for ollama provider.
2. We are optimizing for small models with no memory, so we have to implement a RAG-like solution for providing it context each query. Ideally, each user prompt will list files modified, remember the prompt, store the current git commit, and generate a 1-2 sentence summary of changes, and store these actions in a(n SQL) database. The last N summaries will be injected into each prompt.
3. We need a prompt management layer. And I want to keep the number of hardcoded system prompt templates to a minimum. Ideally 1. But, at the least, we need a system to inject context each user prompt. 
4. For each user prompt, develop a plan of action based on system prompt template that lists available tools and recent context with the user prompt. This plan is a list of JSON objects representing tool use or other actions. This is generated in one call before plan execution.
5. Destructive tools require confirmation before use.
6. Ability to modify generated plans by inserting automatic pre-actions, such as brainstorming search terms or scanning relevant files before proceeding with core actions.

Utilities:
1. Utility to parse the largest JSON object from the model response and strip any "thinking" tags or excess natural language.

Required tools:
1. It should be able to read, write, and search through files. 
2. It should be able to brainstorm relevant search terms and execute them.
3. It should be able to analyze code, and summarize, refactor, or read additional files needed for context.
4. It should be able to create folders and files, and then write to them.
5. It should be able to access git information.
6. It should be able to run tests (static tests, linters, and unit tests).
7. It should be able to add documentation to files.
8. Using the above skills, it should be able to debug issues.
9. (See required techologies) we should also have an automatic search over similar recent prompts from the RAG database
10. Search with ripgrep.
11. Generate diffs (even if just git diff tool)
12. Index the codebase for fast searching (this index is automatically built and updated when changes are made. Is it possible to build the index so changing a file doesn't require rebuilding the entire index?)

Additional thoughts:
1. tool_schema.json registry: Keep a single source of truth for tool names, inputs, and expected output shapes. Helps with prompting.
2. “Action executor” loop: One-shot plan → multi-step execution of tools, each result passed back into prompt (like LangGraph).
3. Auto-indexer: watchman or fswatch to track file changes. Only re-index touched files.
4. Auto-debug via test failure logs → plan trace + read code + re-test.
5. Command routing fallback: If model gives raw command (e.g., npm run test), validate and execute it in sandbox.
6. Other prompts such as writing or generating code will require injecting "return only code, nothing else" in the prompt layer.
7. Cache file read results per commit (with hash) to avoid rereading unchanged files or chunks unless prompted. Useful when planning multiple steps.
8. Also, cache file summarizes per commit. 